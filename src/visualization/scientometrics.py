# -*- coding: utf-8 -*-

import os
import json
import re
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import powerlaw
from matplotlib.backends.backend_pdf import PdfPages
import contextlib
import sys


# ============================================================
# Core utilities & Analysis (Mathematical Logic)
# ============================================================

class ScientometricsAnalyzer:
    """
    Core analytical utilities for scientometric evaluation.

    Responsibilities:
    - robust parsing of serialized distributions
    - memory-safe Kolmogorov–Smirnov distance computation
    - power-law fitting using Maximum Likelihood Estimation (MLE)
    """

    def robust_load(self, data_str):
        """
        Parse dictionary-like strings into native Python dictionaries.

        Handles common serialization issues:
        - integer keys not quoted (non-JSON)
        - single vs double quotes
        - Python literal representations
        """
        if not isinstance(data_str, str):
            return data_str

        try:
            formatted = re.sub(r'(\s*)(\d+):', r'\1"\2":', data_str)
            formatted = formatted.replace("'", '"')
            return json.loads(formatted)
        except Exception:
            import ast
            return ast.literal_eval(data_str)

    def calculate_ks(self, exp_cit_dist, ref_cit_dist):
        """
        Compute the Kolmogorov–Smirnov statistic using binned frequencies.

        This implementation avoids explicit reconstruction of raw
        observation vectors to prevent excessive memory usage.
        """
        support = sorted(set(exp_cit_dist) | set(ref_cit_dist))

        exp_counts = np.array([exp_cit_dist.get(x, 0) for x in support], dtype=float)
        ref_counts = np.array([ref_cit_dist.get(x, 0) for x in support], dtype=float)

        exp_cdf = np.cumsum(exp_counts) / exp_counts.sum()
        ref_cdf = np.cumsum(ref_counts) / ref_counts.sum()

        return np.max(np.abs(exp_cdf - ref_cdf))

    def get_citation_array(self, citation_dist):
        """
        Expand frequency counts into raw observations.

        Required for statistical procedures that operate on
        individual samples (e.g. power-law MLE fitting).
        """
        data = []
        for value, freq in citation_dist.items():
            data.extend([int(value)] * int(freq))
        return np.array(data)

    def get_powerlaw_fit(self, citation_dist):
        """
        Fit a discrete power-law model using Maximum Likelihood Estimation.

        Returns:
            powerlaw.Fit: fitted power-law model object
        """
        data = self.get_citation_array(citation_dist)
        data = data[data > 0]  # Power-law models require strictly positive values
        
        # Use contextlib to swallow any stdout/stderr generated by the library
        with contextlib.redirect_stdout(open(os.devnull, 'w')):
            with contextlib.redirect_stderr(open(os.devnull, 'w')):
                fit = powerlaw.Fit(data, discrete=True, verbose=False)
        return fit


# ============================================================
# Stage 1 — Empirical overlap verification (Visual)
# ============================================================

class ImpactDistributionVisualizer:
    """
    Empirical verification stage.

    Focuses on direct visual comparison between simulation
    and empirical data using:
    - raw frequency overlap (PDF / Zipf plot)
    - standard cumulative distribution (CDF)
    """

    def get_cdf_data(self, citation_dist):
        """
        Construct a monotonic cumulative distribution function (CDF)
        from a citation frequency dictionary.
        """
        xs = sorted(citation_dist)
        ys = np.cumsum([citation_dist[x] for x in xs])
        ys = ys / ys[-1]
        return np.array(xs), ys

    def plot_page(self, exp_cit_dist, ref_cit_dist, ks_stat, label, pdf_handle):
        """
        Render an empirical comparison page.

        The page contains:
        - PDF overlap (log-log)
        - rising CDF comparison

        Returns:
            float: KS statistic (propagated for downstream ranking)
        """
        exp_pdf = pd.DataFrame(exp_cit_dist.items(), columns=["C", "F"]).sort_values("C")
        ref_pdf = pd.DataFrame(ref_cit_dist.items(), columns=["C", "F"]).sort_values("C")

        exp_x, exp_y = self.get_cdf_data(exp_cit_dist)
        ref_x, ref_y = self.get_cdf_data(ref_cit_dist)

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))

        ax1.loglog(
            ref_pdf["C"], ref_pdf["F"],
            's-', color='navy', alpha=0.3, markersize=3, label="Empirical"
        )
        ax1.loglog(
            exp_pdf["C"], exp_pdf["F"],
            'o-', color='crimson', alpha=0.7, markersize=3, label="Simulation"
        )
        ax1.set_title("PDF: Citation Frequency Overlap")
        ax1.legend()

        ax2.step(ref_x, ref_y, color='navy', linewidth=2, label="Empirical")
        ax2.step(exp_x, exp_y, '--', color='crimson', linewidth=2, label="Simulation")
        ax2.set_xscale("log")
        ax2.set_title("CDF: Citation Accumulation")
        ax2.legend()

        plt.suptitle(
            f"EMPIRICAL VERIFICATION | {label}\nKS = {ks_stat:.4f}",
            fontsize=12
        )

        pdf_handle.savefig(fig)
        plt.close(fig)

        # Explicit return enables global ranking and model selection
        return ks_stat


# ============================================================
# Stage 2 — Power Law and tail analysis (Visual)
# ============================================================

class PowerLawAnalyticalVisualizer:
    """
    Theoretical validation stage.

    Focuses on:
    - power-law fitting via MLE
    - tail behavior analysis using CCDF
    """

    def plot_page(self, fit_exp, fit_ref, ks_stat, label, pdf_handle):
        """
        Render theoretical comparison page.

        The page contains:
        - PDF with fitted power-law slopes
        - CCDF for tail behavior inspection

        Returns:
            float: KS statistic (propagated for downstream ranking)
        """
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))

        fit_ref.plot_pdf(color='navy', ax=ax1, label="Empirical")
        fit_ref.power_law.plot_pdf(
            color='navy', linestyle='--', alpha=0.2, ax=ax1
        )

        fit_exp.plot_pdf(color='crimson', ax=ax1, label="Simulation")
        fit_exp.power_law.plot_pdf(
            color='crimson', linestyle='--', alpha=0.2, ax=ax1
        )

        ax1.set_title("PDF: Power Law Fit")
        ax1.legend()

        fit_ref.plot_ccdf(color='navy', ax=ax2, label="Empirical")
        fit_exp.plot_ccdf(
            color='crimson', linestyle='--', ax=ax2, label="Simulation"
        )

        ax2.set_title("CCDF: Tail Behavior")
        ax2.legend()

        plt.suptitle(
            f"THEORETICAL VALIDATION | {label}\n"
            f"KS = {ks_stat:.4f} | Alpha_sim = {fit_exp.alpha:.2f}",
            fontsize=12
        )

        pdf_handle.savefig(fig)
        plt.close(fig)

        # Explicit return enables unified scoring across validation stages
        return ks_stat
